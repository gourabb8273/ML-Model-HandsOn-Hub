{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprossing -  Word embedding (with out using Neural Network) for NLP\n",
    "#### we will be using NLTK Natural Language Processing Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking random CORPUS from google using multi line comments\n",
    "paragraph = \"\"\"Modi was born and raised in Vadnagar in northeastern Gujarat, where he completed his secondary education. He was introduced to the RSS at the age of eight. His account of helping his father sell tea at the Vadnagar railway station has not been reliably corroborated. At age 18, he was married to Jashodaben Modi, whom he abandoned soon after, only publicly acknowledging her four decades later when legally required to do so. Modi became a full-time worker for the RSS in Gujarat in 1971. The RSS assigned him to the BJP in 1985 and he held several positions within the party hierarchy until 2001, rising to the rank of general secretary\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modi was born and raised in Vadnagar in northeastern Gujarat, where he completed his secondary education. He was introduced to the RSS at the age of eight. His account of helping his father sell tea at the Vadnagar railway station has not been reliably corroborated. At age 18, he was married to Jashodaben Modi, whom he abandoned soon after, only publicly acknowledging her four decades later when legally required to do so. Modi became a full-time worker for the RSS in Gujarat in 1971. The RSS assigned him to the BJP in 1985 and he held several positions within the party hierarchy until 2001, rising to the rank of general secretary'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing NLTK libraries for stemming and stop words\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Tokenization - converting paragraph to sentences then words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\goura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')  # need to download punkt in nltk for tokenization\n",
    "sentences = nltk.sent_tokenize(paragraph) #converting paragraph into sentences as list of element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modi was born and raised in Vadnagar in northeastern Gujarat, where he completed his secondary education.',\n",
       " 'He was introduced to the RSS at the age of eight.',\n",
       " 'His account of helping his father sell tea at the Vadnagar railway station has not been reliably corroborated.',\n",
       " 'At age 18, he was married to Jashodaben Modi, whom he abandoned soon after, only publicly acknowledging her four decades later when legally required to do so.',\n",
       " 'Modi became a full-time worker for the RSS in Gujarat in 1971.',\n",
       " 'The RSS assigned him to the BJP in 1985 and he held several positions within the party hierarchy until 2001, rising to the rank of general secretary']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences # containing list of sentences from paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The RSS assigned him to the BJP in 1985 and he held several positions within the party hierarchy until 2001, rising to the rank of general secretary'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stemming - finding base root word from multiple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"going\") # it will convert it to base word like go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"thinking\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lemmatization - finding meaningful word from dictionary from multiple words (Alternative of Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thinking'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('thinking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('finally')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning the entire text like special char using regex\n",
    "- Applying regex\n",
    "- Applying Lowering case\n",
    "- Applying Lemmatization\n",
    "- Applying stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modi born raised vadnagar northeastern gujarat completed secondary education',\n",
       " 'introduced r age eight',\n",
       " 'account helping father sell tea vadnagar railway station reliably corroborated',\n",
       " 'age married jashodaben modi abandoned soon publicly acknowledging four decade later legally required',\n",
       " 'modi became full time worker r gujarat',\n",
       " 'r assigned bjp held several position within party hierarchy rising rank general secretary']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review =re.sub('[^a-zA-Z]',' ',sentences[i]) # other than a to z any word convert it to \" \" and update\n",
    "    review=review.lower()  # lowering the words\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in set (stopwords.words(\"english\")) ]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review) \n",
    "\n",
    "corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english') # checking stop words not significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Applying Stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modi\n",
      "born\n",
      "rais\n",
      "vadnagar\n",
      "northeastern\n",
      "gujarat\n",
      ",\n",
      "complet\n",
      "secondari\n",
      "educ\n",
      ".\n",
      "he\n",
      "introduc\n",
      "rss\n",
      "age\n",
      "eight\n",
      ".\n",
      "hi\n",
      "account\n",
      "help\n",
      "father\n",
      "sell\n",
      "tea\n",
      "vadnagar\n",
      "railway\n",
      "station\n",
      "reliabl\n",
      "corrobor\n",
      ".\n",
      "at\n",
      "age\n",
      "18\n",
      ",\n",
      "marri\n",
      "jashodaben\n",
      "modi\n",
      ",\n",
      "abandon\n",
      "soon\n",
      ",\n",
      "publicli\n",
      "acknowledg\n",
      "four\n",
      "decad\n",
      "later\n",
      "legal\n",
      "requir\n",
      ".\n",
      "modi\n",
      "becam\n",
      "full-tim\n",
      "worker\n",
      "rss\n",
      "gujarat\n",
      "1971\n",
      ".\n",
      "the\n",
      "rss\n",
      "assign\n",
      "bjp\n",
      "1985\n",
      "held\n",
      "sever\n",
      "posit\n",
      "within\n",
      "parti\n",
      "hierarchi\n",
      "2001\n",
      ",\n",
      "rise\n",
      "rank\n",
      "gener\n",
      "secretari\n"
     ]
    }
   ],
   "source": [
    "for i in sentences:\n",
    "    words=nltk.word_tokenize(i) # getting word from sentences\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words(\"english\")): # if word not belong to stop word then stemming it\n",
    "            print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Applying Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modi\n",
      "born\n",
      "raised\n",
      "Vadnagar\n",
      "northeastern\n",
      "Gujarat\n",
      ",\n",
      "completed\n",
      "secondary\n",
      "education\n",
      ".\n",
      "He\n",
      "introduced\n",
      "RSS\n",
      "age\n",
      "eight\n",
      ".\n",
      "His\n",
      "account\n",
      "helping\n",
      "father\n",
      "sell\n",
      "tea\n",
      "Vadnagar\n",
      "railway\n",
      "station\n",
      "reliably\n",
      "corroborated\n",
      ".\n",
      "At\n",
      "age\n",
      "18\n",
      ",\n",
      "married\n",
      "Jashodaben\n",
      "Modi\n",
      ",\n",
      "abandoned\n",
      "soon\n",
      ",\n",
      "publicly\n",
      "acknowledging\n",
      "four\n",
      "decade\n",
      "later\n",
      "legally\n",
      "required\n",
      ".\n",
      "Modi\n",
      "became\n",
      "full-time\n",
      "worker\n",
      "RSS\n",
      "Gujarat\n",
      "1971\n",
      ".\n",
      "The\n",
      "RSS\n",
      "assigned\n",
      "BJP\n",
      "1985\n",
      "held\n",
      "several\n",
      "position\n",
      "within\n",
      "party\n",
      "hierarchy\n",
      "2001\n",
      ",\n",
      "rising\n",
      "rank\n",
      "general\n",
      "secretary\n"
     ]
    }
   ],
   "source": [
    "for i in sentences:\n",
    "    words=nltk.word_tokenize(i) # getting word from sentences\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words(\"english\")): # if word not belong to stop word then stemming it\n",
    "            print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Checking the vocabulay with index \n",
    "\n",
    "an unique index will be assigned to each word to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modi': 26,\n",
       " 'born': 7,\n",
       " 'raised': 32,\n",
       " 'vadnagar': 45,\n",
       " 'northeastern': 27,\n",
       " 'gujarat': 17,\n",
       " 'completed': 8,\n",
       " 'secondary': 37,\n",
       " 'education': 11,\n",
       " 'introduced': 21,\n",
       " 'age': 3,\n",
       " 'eight': 12,\n",
       " 'account': 1,\n",
       " 'helping': 19,\n",
       " 'father': 13,\n",
       " 'sell': 39,\n",
       " 'tea': 43,\n",
       " 'railway': 31,\n",
       " 'station': 42,\n",
       " 'reliably': 34,\n",
       " 'corroborated': 9,\n",
       " 'married': 25,\n",
       " 'jashodaben': 22,\n",
       " 'abandoned': 0,\n",
       " 'soon': 41,\n",
       " 'publicly': 30,\n",
       " 'acknowledging': 2,\n",
       " 'four': 14,\n",
       " 'decade': 10,\n",
       " 'later': 23,\n",
       " 'legally': 24,\n",
       " 'required': 35,\n",
       " 'became': 5,\n",
       " 'full': 15,\n",
       " 'time': 44,\n",
       " 'worker': 47,\n",
       " 'assigned': 4,\n",
       " 'bjp': 6,\n",
       " 'held': 18,\n",
       " 'several': 40,\n",
       " 'position': 29,\n",
       " 'within': 46,\n",
       " 'party': 28,\n",
       " 'hierarchy': 20,\n",
       " 'rising': 36,\n",
       " 'rank': 33,\n",
       " 'general': 16,\n",
       " 'secretary': 38}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_ # this will give u index not frequency it is feature number like f1 f2 to fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2 Checking bag of words for first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modi born raised vadnagar northeastern gujarat completed secondary education'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0] # first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(X[0].toarray()[0])\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " These 48 words are feature unigram. Now wherever we found word belong to first sentence we wil get the count 1\n",
    "\n",
    "in the first sentence we have word as \"and\" whose index is 5 hence in 5th index we can see count 1, 32 index is \"in\" whose count is 2 as repeating 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3 Converting to Binary Bag of word anything apperaring more than 1 will be considered as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv_binary=CountVectorizer(binary=True)\n",
    "X_binray= cv_binary.fit_transform(corpus)\n",
    "X_binray[0].toarray() # all 2 are gone all will be 1 if count is more than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These is the problem of Sparsity  which is really bad for large data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.4 Using Ngram in Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating only trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modi born raised': 23,\n",
       " 'born raised vadnagar': 7,\n",
       " 'raised vadnagar northeastern': 29,\n",
       " 'vadnagar northeastern gujarat': 38,\n",
       " 'northeastern gujarat completed': 24,\n",
       " 'gujarat completed secondary': 13,\n",
       " 'completed secondary education': 8,\n",
       " 'introduced age eight': 17,\n",
       " 'account helping father': 1,\n",
       " 'helping father sell': 15,\n",
       " 'father sell tea': 10,\n",
       " 'sell tea vadnagar': 32,\n",
       " 'tea vadnagar railway': 36,\n",
       " 'vadnagar railway station': 39,\n",
       " 'railway station reliably': 28,\n",
       " 'station reliably corroborated': 35,\n",
       " 'age married jashodaben': 3,\n",
       " 'married jashodaben modi': 20,\n",
       " 'jashodaben modi abandoned': 18,\n",
       " 'modi abandoned soon': 21,\n",
       " 'abandoned soon publicly': 0,\n",
       " 'soon publicly acknowledging': 34,\n",
       " 'publicly acknowledging four': 27,\n",
       " 'acknowledging four decade': 2,\n",
       " 'four decade later': 11,\n",
       " 'decade later legally': 9,\n",
       " 'later legally required': 19,\n",
       " 'modi became full': 22,\n",
       " 'became full time': 5,\n",
       " 'full time worker': 12,\n",
       " 'time worker gujarat': 37,\n",
       " 'assigned bjp held': 4,\n",
       " 'bjp held several': 6,\n",
       " 'held several position': 14,\n",
       " 'several position within': 33,\n",
       " 'position within party': 26,\n",
       " 'within party hierarchy': 40,\n",
       " 'party hierarchy rising': 25,\n",
       " 'hierarchy rising rank': 16,\n",
       " 'rising rank general': 31,\n",
       " 'rank general secretary': 30}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_trigram=CountVectorizer(binary=True,ngram_range=(3,3))   # creating only trigram\n",
    "X_trigram= cv_trigram.fit_transform(corpus)\n",
    "cv_trigram.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating both Bi and Tri gram   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modi born': 49,\n",
       " 'born raised': 15,\n",
       " 'raised vadnagar': 61,\n",
       " 'vadnagar northeastern': 81,\n",
       " 'northeastern gujarat': 51,\n",
       " 'gujarat completed': 28,\n",
       " 'completed secondary': 17,\n",
       " 'secondary education': 68,\n",
       " 'modi born raised': 50,\n",
       " 'born raised vadnagar': 16,\n",
       " 'raised vadnagar northeastern': 62,\n",
       " 'vadnagar northeastern gujarat': 82,\n",
       " 'northeastern gujarat completed': 52,\n",
       " 'gujarat completed secondary': 29,\n",
       " 'completed secondary education': 18,\n",
       " 'introduced age': 36,\n",
       " 'age eight': 6,\n",
       " 'introduced age eight': 37,\n",
       " 'account helping': 2,\n",
       " 'helping father': 32,\n",
       " 'father sell': 21,\n",
       " 'sell tea': 69,\n",
       " 'tea vadnagar': 77,\n",
       " 'vadnagar railway': 83,\n",
       " 'railway station': 59,\n",
       " 'station reliably': 75,\n",
       " 'reliably corroborated': 65,\n",
       " 'account helping father': 3,\n",
       " 'helping father sell': 33,\n",
       " 'father sell tea': 22,\n",
       " 'sell tea vadnagar': 70,\n",
       " 'tea vadnagar railway': 78,\n",
       " 'vadnagar railway station': 84,\n",
       " 'railway station reliably': 60,\n",
       " 'station reliably corroborated': 76,\n",
       " 'age married': 7,\n",
       " 'married jashodaben': 43,\n",
       " 'jashodaben modi': 38,\n",
       " 'modi abandoned': 45,\n",
       " 'abandoned soon': 0,\n",
       " 'soon publicly': 73,\n",
       " 'publicly acknowledging': 57,\n",
       " 'acknowledging four': 4,\n",
       " 'four decade': 23,\n",
       " 'decade later': 19,\n",
       " 'later legally': 40,\n",
       " 'legally required': 42,\n",
       " 'age married jashodaben': 8,\n",
       " 'married jashodaben modi': 44,\n",
       " 'jashodaben modi abandoned': 39,\n",
       " 'modi abandoned soon': 46,\n",
       " 'abandoned soon publicly': 1,\n",
       " 'soon publicly acknowledging': 74,\n",
       " 'publicly acknowledging four': 58,\n",
       " 'acknowledging four decade': 5,\n",
       " 'four decade later': 24,\n",
       " 'decade later legally': 20,\n",
       " 'later legally required': 41,\n",
       " 'modi became': 47,\n",
       " 'became full': 11,\n",
       " 'full time': 25,\n",
       " 'time worker': 79,\n",
       " 'worker gujarat': 87,\n",
       " 'modi became full': 48,\n",
       " 'became full time': 12,\n",
       " 'full time worker': 26,\n",
       " 'time worker gujarat': 80,\n",
       " 'assigned bjp': 9,\n",
       " 'bjp held': 13,\n",
       " 'held several': 30,\n",
       " 'several position': 71,\n",
       " 'position within': 55,\n",
       " 'within party': 85,\n",
       " 'party hierarchy': 53,\n",
       " 'hierarchy rising': 34,\n",
       " 'rising rank': 66,\n",
       " 'rank general': 63,\n",
       " 'general secretary': 27,\n",
       " 'assigned bjp held': 10,\n",
       " 'bjp held several': 14,\n",
       " 'held several position': 31,\n",
       " 'several position within': 72,\n",
       " 'position within party': 56,\n",
       " 'within party hierarchy': 86,\n",
       " 'party hierarchy rising': 54,\n",
       " 'hierarchy rising rank': 35,\n",
       " 'rising rank general': 67,\n",
       " 'rank general secretary': 64}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_bi_trigram=CountVectorizer(binary=True,ngram_range=(2,3))   # creating both bi and trigram\n",
    "X_bi_trigram= cv_bi_trigram.fit_transform(corpus)\n",
    "cv_bi_trigram.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv_tfidf = TfidfVectorizer()\n",
    "X_tfidf=cv_tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modi born raised vadnagar northeastern gujarat completed secondary education'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35750457, 0.35750457, 0.        ,\n",
       "        0.        , 0.35750457, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29315886, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24750486, 0.35750457, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35750457, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.35750457, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.29315886, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can see different weightage those which are common appearing multiple time are having less or 0 weightage and those are rarely appreading having more weightage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1 Using Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv_tfidf_tri = TfidfVectorizer(ngram_range=(3,3))\n",
    "X_tfidf_tri=cv_tfidf_tri.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.37796447, 0.37796447, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37796447, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37796447, 0.37796447,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37796447, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_tri[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here weightage are now different w.r.t Trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2 Using max feature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv_tfidf_max_feature = TfidfVectorizer(ngram_range=(1,1),max_features=10)\n",
    "X_tfidf_max_feature=cv_tfidf_max_feature.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.48795307, 0.41196351, 0.59505434,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.48795307]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_max_feature[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now vector is reduced as we put a limit as 10 so we will get top 10 max feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
