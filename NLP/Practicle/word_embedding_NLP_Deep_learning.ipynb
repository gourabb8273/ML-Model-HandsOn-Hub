{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw-KJnsN-lSQ"
      },
      "source": [
        "\n",
        "## **Word Embedding - NLP with Deep Learning** ([Using Google Colab]([text](https://colab.research.google.com/drive/1NkJmlUZWK21flAkqsxV86tXbaORRH5ys?authuser=5#scrollTo=-uqVOAju1zTa)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uqVOAju1zTa",
        "outputId": "adc6066f-30c7-49b5-8d4b-318102f0bb4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VvXGNjOx2FcI"
      },
      "outputs": [],
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Pa1HUK-P6Q"
      },
      "source": [
        "Taking a corpus or sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6BRcKzjz2LW6"
      },
      "outputs": [],
      "source": [
        "### Sample sentences or corpus\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLIwpFam2PJq",
        "outputId": "b375a589-784e-4de1-d406-175f3bc6fb6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFXBwhL42jdY"
      },
      "source": [
        "Now we have to define the **vocabulary size** which will be like a hyper parameter tuning. Based on the size our words will get indexed. Say If I choose 100 then all of my word will get indexed in between 1 to 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NHXJ3XAr2d58"
      },
      "outputs": [],
      "source": [
        "voc_size =10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMrprMap3HGL"
      },
      "source": [
        "### 1. One Hot Representation of the words\n",
        "\n",
        "After OHE each word will become index number based on vocabulary size we mentioned. So we will get array of index\n",
        "e.g."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yjuEyte27qQ",
        "outputId": "3a10dd0b-6ed7-4c7d-d32e-8c0ce477065a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3741, 615, 135, 245], [3741, 615, 135, 6998], [3741, 926, 135, 8206], [7249, 3753, 6665, 7492, 7506], [7249, 3753, 6665, 7492, 5082], [2240, 3741, 9692, 135, 5878], [9704, 3152, 8309, 7492]]\n",
            "First sentence : the glass of milk\n",
            "OHE representation : [3741, 615, 135, 245]\n"
          ]
        }
      ],
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
        "print(onehot_repr)\n",
        "\n",
        "print(f\"First sentence : {sent[0]}\")\n",
        "print(f\"OHE representation : {onehot_repr[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXwJujYP4IXT"
      },
      "source": [
        "### 2. Word Embedding Representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OJ6-BpUf3NJK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding # This will do the embedding like converts to word2vec\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This will add padding to make same length of all sentence\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v1_3JIzY4fhK"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3WfcynG46-j"
      },
      "source": [
        "### 2.1. Padding\n",
        "Now as we see sentence length is not fixed but we need same length as input feature so we can add padding like adding 0 in last for post padding and in begining for pre padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpjzXtof4izF",
        "outputId": "65563f1f-4199-4da8-f4ab-195945f62085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0 3741  615  135  245]\n",
            " [   0    0    0    0 3741  615  135 6998]\n",
            " [   0    0    0    0 3741  926  135 8206]\n",
            " [   0    0    0 7249 3753 6665 7492 7506]\n",
            " [   0    0    0 7249 3753 6665 7492 5082]\n",
            " [   0    0    0 2240 3741 9692  135 5878]\n",
            " [   0    0    0    0 9704 3152 8309 7492]]\n"
          ]
        }
      ],
      "source": [
        "sent_length= 8 # assuming worst case scenario highest length of sentence available in corpus is 8\n",
        "embedded_docs=pad_sequences(onehot_repr, padding='pre',maxlen=sent_length) # For pre 0 will be added at begining\n",
        "print(embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4elqSow5YHI"
      },
      "source": [
        "Let's see now my first sentence or document and it's OHE representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZWM8aN35RLL",
        "outputId": "433f7ef8-57a2-4fa0-cf47-f3ba101110fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First sentence : the glass of milk\n",
            "OHE representation : [   0    0    0    0 3741  615  135  245]\n"
          ]
        }
      ],
      "source": [
        "print(f\"First sentence : {sent[0]}\")\n",
        "print(f\"OHE representation : {embedded_docs[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoSbMGmu54zX"
      },
      "source": [
        "### 2.2. Feature Representation\n",
        "Now we have done OHE next step is each word in sentence which is index of vocabulary will be represented as **vector of some dimension** that's called feature representation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vSdPbov75hwM"
      },
      "outputs": [],
      "source": [
        "dim = 10 # for large data set we can have 300 dimension for each word which is sufficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Sba-2LX877Zo"
      },
      "outputs": [],
      "source": [
        "model=Sequential() # The Sequential model is a linear stack of layers, where you can add layers one by one.\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length)) # adding an Embedding layer to the model which will work as word2vec\n",
        "model.compile('adam','mse') # compiling the model using the Adam optimizer and Mean Squared Error (MSE) as the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ4b4c4o8WCb",
        "outputId": "27d8707b-a259-49cc-823d-1001538752ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 8, 10)             100000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100000 (390.62 KB)\n",
            "Trainable params: 100000 (390.62 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCLYBWNB8_VD"
      },
      "source": [
        "let's see my first sentences after word embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOtxcix38ia9",
        "outputId": "eddcc920-f57c-45ae-bc58-7c839a7f9bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My first sentence\n",
            "the glass of milk\n",
            "=========================\n",
            "After One Hot Encoding\n",
            "[   0    0    0    0 3741  615  135  245]\n",
            "=========================\n",
            "After Embedding\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "[[ 0.02334119  0.02603856 -0.02011134  0.03384751  0.04289399  0.04751729\n",
            "   0.01939005  0.02223737  0.03556294  0.03270935]\n",
            " [ 0.02334119  0.02603856 -0.02011134  0.03384751  0.04289399  0.04751729\n",
            "   0.01939005  0.02223737  0.03556294  0.03270935]\n",
            " [ 0.02334119  0.02603856 -0.02011134  0.03384751  0.04289399  0.04751729\n",
            "   0.01939005  0.02223737  0.03556294  0.03270935]\n",
            " [ 0.02334119  0.02603856 -0.02011134  0.03384751  0.04289399  0.04751729\n",
            "   0.01939005  0.02223737  0.03556294  0.03270935]\n",
            " [-0.04506241  0.01671313 -0.03848625 -0.00520509  0.00547225  0.03812024\n",
            "  -0.0225917   0.00381789  0.02134356  0.03596712]\n",
            " [-0.04015439  0.00291693  0.0259621  -0.02744615  0.02922304 -0.03540211\n",
            "  -0.04640775  0.02629754  0.01908923  0.01543989]\n",
            " [-0.01597004 -0.0012911  -0.00037912 -0.03518567  0.04150781  0.02370092\n",
            "  -0.04217914  0.04465172  0.04971534 -0.01529777]\n",
            " [-0.02601907 -0.02863796  0.0450714   0.02239725 -0.0469184  -0.00338397\n",
            "  -0.02776437  0.04241088  0.01147617 -0.01685302]]\n"
          ]
        }
      ],
      "source": [
        "print(\"My first sentence\")\n",
        "print(sent[0])\n",
        "print(\"=========================\")\n",
        "print(\"After One Hot Encoding\")\n",
        "print(embedded_docs[0])\n",
        "print(\"=========================\")\n",
        "print(\"After Embedding\")\n",
        "print(model.predict(embedded_docs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luIB4R8L9rUU"
      },
      "source": [
        "let's see the feature representation in 10 dimension for word **glass**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvOapEeJ9U7s",
        "outputId": "ae1074bf-aefe-4bcd-9611-0cde235ac7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 13ms/step\n",
            "[ 0.02334119  0.02603856 -0.02011134  0.03384751  0.04289399  0.04751729\n",
            "  0.01939005  0.02223737  0.03556294  0.03270935]\n"
          ]
        }
      ],
      "source": [
        "print(model.predict(embedded_docs[0])[1]) # 10 dimension of word vector for glass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvQOfwkZ9_lb"
      },
      "source": [
        "### *So we have done the word embedding for the given corpus successfully*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf1BJz5--MxR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
